\begin{tabular}{lrrrrrrrrr}
\toprule
{} &  accuracy &  precision macro &  recall macro &  f1-score macro &  support macro &  precision weighted &  recall weighted &  f1-score weighted &  support weighted \\
\midrule
\_TFIDF\_LogisticRegression(solver='sag')\_           &  0.679593 &         0.474018 &      0.490589 &        0.453367 &        12790.0 &            0.582493 &         0.679593 &           0.609647 &           12790.0 \\
\_KNN\_1                                             &  0.700547 &         0.512728 &      0.503278 &        0.459836 &        12790.0 &            0.606440 &         0.700547 &           0.620085 &           12790.0 \\
\_KNN\_3                                             &  0.718452 &         0.536560 &      0.502251 &        0.432743 &        12790.0 &            0.619469 &         0.718452 &           0.611654 &           12790.0 \\
\_KNN\_5                                             &  0.602502 &         0.496959 &      0.497055 &        0.496889 &        12790.0 &            0.596347 &         0.602502 &           0.599330 &           12790.0 \\
\_KNN\_7                                             &  0.616263 &         0.496696 &      0.497056 &        0.495580 &        12790.0 &            0.596230 &         0.616263 &           0.605228 &           12790.0 \\
\_KNN\_10                                            &  0.668804 &         0.501475 &      0.500785 &        0.481898 &        12790.0 &            0.599729 &         0.668804 &           0.620192 &           12790.0 \\
\_TFIDF\_DecisionTreeClassifier()\_                   &  0.607115 &         0.497979 &      0.498084 &        0.497717 &        12790.0 &            0.597168 &         0.607115 &           0.601892 &           12790.0 \\
\_TFIDF\_SVC(kernel='linear')\_                       &  0.689601 &         0.475076 &      0.492928 &        0.447956 &        12790.0 &            0.583560 &         0.689601 &           0.610271 &           12790.0 \\
\_ngram\_2\_LogisticRegression(solver='sag')\_         &  0.702033 &         0.493106 &      0.498591 &        0.446643 &        12790.0 &            0.594657 &         0.702033 &           0.613709 &           12790.0 \\
\_ngramKNN\_2k=1                                     &  0.432760 &         0.491684 &      0.490381 &        0.428305 &        12790.0 &            0.589444 &         0.432760 &           0.450732 &           12790.0 \\
\_ngramKNN\_2k=3                                     &  0.438311 &         0.495922 &      0.495264 &        0.433522 &        12790.0 &            0.594200 &         0.438311 &           0.456670 &           12790.0 \\
\_ngramKNN\_2k=5                                     &  0.703675 &         0.534445 &      0.509513 &        0.470841 &        12790.0 &            0.619690 &         0.703675 &           0.626832 &           12790.0 \\
\_ngramKNN\_2k=7                                     &  0.707584 &         0.530899 &      0.506591 &        0.459613 &        12790.0 &            0.617147 &         0.707584 &           0.622294 &           12790.0 \\
\_ngramKNN\_2k=10                                    &  0.714855 &         0.504359 &      0.500367 &        0.433078 &        12790.0 &            0.601239 &         0.714855 &           0.610700 &           12790.0 \\
\_ngram\_2\_DecisionTreeClassifier()\_                 &  0.711493 &         0.527402 &      0.504188 &        0.448526 &        12790.0 &            0.614746 &         0.711493 &           0.617763 &           12790.0 \\
\_ngram\_2\_SVC(kernel='linear')\_                     &  0.713995 &         0.534108 &      0.504361 &        0.445495 &        12790.0 &            0.618499 &         0.713995 &           0.616973 &           12790.0 \\
\_ngram\_3\_LogisticRegression(max\_iter=10000, n\_j... &  0.720954 &         0.582112 &      0.504243 &        0.434492 &        12790.0 &            0.645135 &         0.720954 &           0.613362 &           12790.0 \\
\_ngramKNN\_3k=1                                     &  0.293901 &         0.485851 &      0.497209 &        0.252063 &        12790.0 &            0.578833 &         0.293901 &           0.173449 &           12790.0 \\
\_ngramKNN\_3k=3                                     &  0.294371 &         0.481381 &      0.496061 &        0.253722 &        12790.0 &            0.572591 &         0.294371 &           0.176319 &           12790.0 \\
\_ngramKNN\_3k=5                                     &  0.294527 &         0.482653 &      0.496343 &        0.253830 &        12790.0 &            0.574376 &         0.294527 &           0.176386 &           12790.0 \\
\_ngramKNN\_3k=7                                     &  0.293354 &         0.484499 &      0.497003 &        0.251160 &        12790.0 &            0.576917 &         0.293354 &           0.172164 &           12790.0 \\
\_ngramKNN\_3k=10                                    &  0.294840 &         0.485588 &      0.496992 &        0.253987 &        12790.0 &            0.578494 &         0.294840 &           0.176404 &           12790.0 \\
\_ngram\_3\_SVC(kernel='linear')\_                     &  0.720407 &         0.572267 &      0.504037 &        0.434784 &        12790.0 &            0.639629 &         0.720407 &           0.613345 &           12790.0 \\
\_ngram\_3\_DecisionTreeClassifier()\_                 &  0.719937 &         0.566330 &      0.504059 &        0.435610 &        12790.0 &            0.636335 &         0.719937 &           0.613636 &           12790.0 \\
\bottomrule
\end{tabular}
