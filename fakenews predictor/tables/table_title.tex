\begin{tabular}{lrrrrrrrrr}
\toprule
{} &  accuracy &  precision macro &  recall macro &  f1-score macro &  support macro &  precision weighted &  recall weighted &  f1-score weighted &  support weighted \\
\midrule
\_TFIDF\_LogisticRegression(solver='sag')\_           &  0.794400 &         0.804031 &      0.728069 &        0.745114 &        15000.0 &            0.798750 &         0.794400 &           0.780024 &           15000.0 \\
\_KNN\_1                                             &  0.730267 &         0.712028 &      0.653550 &        0.661827 &        15000.0 &            0.721685 &         0.730267 &           0.709212 &           15000.0 \\
\_KNN\_3                                             &  0.738200 &         0.765252 &      0.638352 &        0.641480 &        15000.0 &            0.753667 &         0.738200 &           0.699480 &           15000.0 \\
\_KNN\_5                                             &  0.672600 &         0.632232 &      0.624710 &        0.627389 &        15000.0 &            0.664873 &         0.672600 &           0.667815 &           15000.0 \\
\_KNN\_7                                             &  0.676933 &         0.635025 &      0.622173 &        0.625819 &        15000.0 &            0.665542 &         0.676933 &           0.668894 &           15000.0 \\
\_KNN\_10                                            &  0.701267 &         0.670401 &      0.615387 &        0.617762 &        15000.0 &            0.685824 &         0.701267 &           0.673408 &           15000.0 \\
\_TFIDF\_DecisionTreeClassifier()\_                   &  0.754400 &         0.728096 &      0.716839 &        0.721465 &        15000.0 &            0.749870 &         0.754400 &           0.751297 &           15000.0 \\
\_TFIDF\_SVC(kernel='linear')\_                       &  0.795133 &         0.811350 &      0.725317 &        0.743095 &        15000.0 &            0.802770 &         0.795133 &           0.779108 &           15000.0 \\
\_ngram\_2\_LogisticRegression(solver='sag')\_         &  0.723667 &         0.811895 &      0.603309 &        0.587649 &        15000.0 &            0.779071 &         0.723667 &           0.661413 &           15000.0 \\
\_ngramKNN\_2k=1                                     &  0.502400 &         0.619851 &      0.594823 &        0.496140 &        15000.0 &            0.688306 &         0.502400 &           0.478647 &           15000.0 \\
\_ngramKNN\_2k=3                                     &  0.509267 &         0.622609 &      0.599461 &        0.504018 &        15000.0 &            0.690866 &         0.509267 &           0.488127 &           15000.0 \\
\_ngramKNN\_2k=5                                     &  0.718000 &         0.762228 &      0.602805 &        0.590760 &        15000.0 &            0.745088 &         0.718000 &           0.661834 &           15000.0 \\
\_ngramKNN\_2k=7                                     &  0.718600 &         0.772631 &      0.601607 &        0.588013 &        15000.0 &            0.751970 &         0.718600 &           0.660257 &           15000.0 \\
\_ngramKNN\_2k=10                                    &  0.721000 &         0.804561 &      0.600126 &        0.583193 &        15000.0 &            0.773523 &         0.721000 &           0.657841 &           15000.0 \\
\_ngram\_2\_DecisionTreeClassifier()\_                 &  0.722733 &         0.800465 &      0.603517 &        0.588786 &        15000.0 &            0.771295 &         0.722733 &           0.661885 &           15000.0 \\
\_ngram\_2\_SVC(kernel='linear')\_                     &  0.723533 &         0.816470 &      0.602471 &        0.586029 &        15000.0 &            0.782059 &         0.723533 &           0.660340 &           15000.0 \\
\_ngram\_3\_LogisticRegression(max\_iter=10000, n\_j... &  0.666333 &         0.803556 &      0.515855 &        0.430138 &        15000.0 &            0.759771 &         0.666333 &           0.544408 &           15000.0 \\
\_ngramKNN\_3k=1                                     &  0.390333 &         0.645575 &      0.532597 &        0.333986 &        15000.0 &            0.734580 &         0.390333 &           0.273649 &           15000.0 \\
\_ngramKNN\_3k=3                                     &  0.390800 &         0.643272 &      0.532722 &        0.334974 &        15000.0 &            0.731535 &         0.390800 &           0.274961 &           15000.0 \\
\_ngramKNN\_3k=5                                     &  0.390533 &         0.649070 &      0.533025 &        0.333951 &        15000.0 &            0.739103 &         0.390533 &           0.273485 &           15000.0 \\
\_ngramKNN\_3k=7                                     &  0.389067 &         0.652017 &      0.532229 &        0.331321 &        15000.0 &            0.743099 &         0.389067 &           0.270117 &           15000.0 \\
\_ngramKNN\_3k=10                                    &  0.388600 &         0.646948 &      0.531505 &        0.331068 &        15000.0 &            0.736555 &         0.388600 &           0.269966 &           15000.0 \\
\_ngram\_3\_SVC(kernel='linear')\_                     &  0.666067 &         0.788685 &      0.515744 &        0.430350 &        15000.0 &            0.749517 &         0.666067 &           0.544483 &           15000.0 \\
\_ngram\_3\_DecisionTreeClassifier()\_                 &  0.665867 &         0.781431 &      0.515591 &        0.430259 &        15000.0 &            0.744501 &         0.665867 &           0.544375 &           15000.0 \\
\bottomrule
\end{tabular}
