\begin{tabular}{lrrrrrrrrr}
\toprule
{} &  accuracy &  precision macro &  recall macro &  f1-score macro &  support macro &  precision weighted &  recall weighted &  f1-score weighted &  support weighted \\
\midrule
\_TFIDF\_LogisticRegression(solver='sag')\_           &  0.935133 &         0.945112 &      0.911999 &        0.925577 &        15000.0 &            0.937442 &         0.935133 &           0.933883 &           15000.0 \\
\_KNN\_1                                             &  0.783600 &         0.761456 &      0.751797 &        0.756011 &        15000.0 &            0.780558 &         0.783600 &           0.781565 &           15000.0 \\
\_KNN\_3                                             &  0.798800 &         0.791599 &      0.747612 &        0.761111 &        15000.0 &            0.796243 &         0.798800 &           0.790665 &           15000.0 \\
\_KNN\_5                                             &  0.809333 &         0.817952 &      0.749435 &        0.767125 &        15000.0 &            0.812981 &         0.809333 &           0.798005 &           15000.0 \\
\_KNN\_7                                             &  0.813733 &         0.837325 &      0.747088 &        0.767309 &        15000.0 &            0.824697 &         0.813733 &           0.799681 &           15000.0 \\
\_KNN\_10                                            &  0.809267 &         0.865305 &      0.728827 &        0.750518 &        15000.0 &            0.838822 &         0.809267 &           0.788225 &           15000.0 \\
\_TFIDF\_DecisionTreeClassifier()\_                   &  0.920933 &         0.913663 &      0.910645 &        0.912121 &        15000.0 &            0.920698 &         0.920933 &           0.920789 &           15000.0 \\
\_TFIDF\_SVC(kernel='linear')\_                       &  0.940133 &         0.945249 &      0.921882 &        0.932006 &        15000.0 &            0.941056 &         0.940133 &           0.939328 &           15000.0 \\
\_ngram\_2\_LogisticRegression(solver='sag')\_         &  0.873267 &         0.901814 &      0.823112 &        0.846528 &        15000.0 &            0.884824 &         0.873267 &           0.866481 &           15000.0 \\
\_ngramKNN\_2k=1                                     &  0.787200 &         0.764841 &      0.775100 &        0.769060 &        15000.0 &            0.792802 &         0.787200 &           0.789219 &           15000.0 \\
\_ngramKNN\_2k=3                                     &  0.839533 &         0.833593 &      0.802725 &        0.814367 &        15000.0 &            0.837947 &         0.839533 &           0.835656 &           15000.0 \\
\_ngramKNN\_2k=5                                     &  0.855200 &         0.864475 &      0.810532 &        0.828291 &        15000.0 &            0.858460 &         0.855200 &           0.849463 &           15000.0 \\
\_ngramKNN\_2k=7                                     &  0.860133 &         0.877067 &      0.812178 &        0.832376 &        15000.0 &            0.866569 &         0.860133 &           0.853621 &           15000.0 \\
\_ngramKNN\_2k=10                                    &  0.866933 &         0.903214 &      0.811522 &        0.836633 &        15000.0 &            0.882663 &         0.866933 &           0.858547 &           15000.0 \\
\_ngram\_2\_DecisionTreeClassifier()\_                 &  0.855200 &         0.841851 &      0.834539 &        0.837950 &        15000.0 &            0.854041 &         0.855200 &           0.854418 &           15000.0 \\
\_ngram\_2\_SVC(kernel='linear')\_                     &  0.893867 &         0.924631 &      0.848385 &        0.872387 &        15000.0 &            0.905808 &         0.893867 &           0.888694 &           15000.0 \\
\_ngram\_3\_LogisticRegression(max\_iter=10000, n\_j... &  0.888733 &         0.922380 &      0.840562 &        0.865385 &        15000.0 &            0.902283 &         0.888733 &           0.882847 &           15000.0 \\
\_ngramKNN\_3k=1                                     &  0.866733 &         0.875959 &      0.825627 &        0.842952 &        15000.0 &            0.869803 &         0.866733 &           0.861987 &           15000.0 \\
\_ngramKNN\_3k=3                                     &  0.883400 &         0.911983 &      0.836081 &        0.859515 &        15000.0 &            0.894636 &         0.883400 &           0.877557 &           15000.0 \\
\_ngramKNN\_3k=5                                     &  0.884733 &         0.916377 &      0.836362 &        0.860639 &        15000.0 &            0.897428 &         0.884733 &           0.878688 &           15000.0 \\
\_ngramKNN\_3k=7                                     &  0.885267 &         0.918237 &      0.836447 &        0.861079 &        15000.0 &            0.898604 &         0.885267 &           0.879134 &           15000.0 \\
\_ngramKNN\_3k=10                                    &  0.885400 &         0.921708 &      0.835169 &        0.860655 &        15000.0 &            0.900424 &         0.885400 &           0.878945 &           15000.0 \\
\_ngram\_3\_SVC(kernel='linear')\_                     &  0.890400 &         0.923989 &      0.842707 &        0.867517 &        15000.0 &            0.903860 &         0.890400 &           0.884666 &           15000.0 \\
\_ngram\_3\_DecisionTreeClassifier()\_                 &  0.886867 &         0.910872 &      0.842772 &        0.864791 &        15000.0 &            0.895818 &         0.886867 &           0.881808 &           15000.0 \\
\bottomrule
\end{tabular}
